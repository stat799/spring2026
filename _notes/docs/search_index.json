[["index.html", "STAT 799 - Topics in Statistics: Applied linear mixed models in agriculture and life sciences Day 1 Welcome to STAT 799! 1.1 About this course: 1.2 Learning goals 1.3 On notation 1.4 Semester project 1.5 Roadmap of this course 1.6 Getting started with statistical modeling 1.7 Review 1.8 The most common statistical model 1.9 Uncertainty", " STAT 799 - Topics in Statistics: Applied linear mixed models in agriculture and life sciences Josefina Lacasa Spring 2026 Day 1 Welcome to STAT 799! January 26th, 2026 1.1 About this course: About me About you: library(tidyverse) library(latex2exp) read.csv(&quot;../../../students_STAT_799_C.csv&quot;) |&gt; filter(degreeProgram != &quot;&quot;) %&gt;% ggplot(aes(x = degreeProgram))+ geom_bar(fill = &quot;#B388EB&quot;)+ theme_bw()+ scale_y_continuous(breaks = 1:9)+ theme(panel.grid.minor = element_blank(), panel.border = element_blank(), axis.title.x = element_blank()) In rounds: What’s your major, what do you expect to learn? 1.1.1 Logistics Website Syllabus Statistical programming requirements Rough mindmap of the course (on whiteboard) Semester project Grades: A (100-89.999999999(!!!)), B (89.99-79.99), C (79.99-69.99), D (69.99-59.99), F (&lt;59.99). Attendance policies Semester projects 1.2 Learning goals By the end of this course, you should be able to: - Identify the data structure for a given dataset and write the statistical model that corresponds to said data structure using statistical notation. - Distinguish the benefits and disadvantages of different modeling approaches. - Write the Materials and Methods section in a paper (or graduate thesis) that describes the data generating process and the statistical model. 1.3 On notation scalars: \\(y\\), \\(\\sigma\\), \\(\\beta_0\\) vectors: \\(\\mathbf{y} \\equiv [y_1, y_2, ..., y_n]&#39;\\), \\(\\boldsymbol{\\beta} \\equiv [\\beta_1, \\beta_2, ..., \\beta_p]&#39;\\), \\(\\boldsymbol{u}\\) matrices: \\(\\mathbf{X}\\), \\(\\Sigma\\) probability distribution: \\(y \\sim N(0, \\sigma^2)\\), \\(\\mathbf{y} \\sim N(\\boldsymbol{0}, \\sigma^2\\mathbf{I})\\). 1.4 Semester project Manuscript Publication-ready analysis Must include Abstract (250w), Introduction (~500w), M&amp;M (~300-500w), Results (~400w), Discussion (~400w), Conclusions (~100w). Last paragraph in the Introduction should clearly state the research gap and the research objectives. [example 1] | [example 2] Reproducible Tutorial Publication-ready tutorial/R documentation [example 1] | [example 2] If you are not sure about your research question yet, talk to me after class today. 1.5 Roadmap of this course .syllabus-table { width: 100%; border-collapse: collapse; font-family: sans-serif; margin: 25px 0; font-size: 0.9em; box-shadow: 0 0 20px rgba(0, 0, 0, 0.1); } .syllabus-table thead tr { background-color: #2c3e50; color: #ffffff; text-align: left; font-weight: bold; } .syllabus-table th, .syllabus-table td { padding: 12px 15px; border: 1px solid #dddddd; } .syllabus-table tbody tr:nth-of-type(even) { background-color: #f3f3f3; } .weekend-row { background-color: #e9ecef !important; text-align: center; font-style: italic; font-weight: bold; color: #6c757d; } .kahoot-yes { color: #46178f; font-weight: bold; } Date Topic Kahoot 01/26 Statistical modeling. Continuous and categorical predictors. Review of mean, variance, and covariance. Types of uncertainty and sources of uncertainty.   01/27 Linear mixed models I. Model diagnostics and model selection.   01/28 Linear mixed models II. Model diagnostics and model selection. Yes 01/29 Analysis of variance.   01/30 Non-linear mixed models I.   Weekend 02/02 Troubleshooting in mixed models fitting using R software. Computational and analytical solutions. Yes 02/03 Generalized linear mixed models I. Beta, Binomial.   02/04 Statistical power in designed experiments   02/05 Statistical inference. Scientific writing. Dos &amp; don’ts.   02/06 Wrap-up Yes Weekend 02/09 Optional: Bayesian modeling &amp; inference   02/10 Optional: Bayesian modeling &amp; inference II   1.6 Getting started with statistical modeling Why do we need statistical models? Statistics as a summary of the data Excerpt from the short story “Funes the memorious” (J.L. Borges): I suspect, however, that he was not very capable of thought. To think is to forget differences, generalize, make abstractions. In the teeming world of Funes, there were only details, almost immediate in their presence. What is a statistical model? Deterministic component + Stochastic component 1.6.1 Writing a statistical model Deterministic component + Stochastic component Example: \\(y_i \\sim N(\\mu_i, \\sigma^2), \\\\ \\mu_i = \\beta_0 + \\beta_1 x_i\\) 1.6.2 What are linear models? Assume that \\(y_i \\sim N(\\mu_i, \\sigma^2)\\). …and there are 4 possible descriptions of the mean: \\(\\mu_i = \\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i}\\) \\(\\mu_i = \\beta_0 + \\beta_1 x_i + \\beta_2 x_i^2\\) \\(\\mu_i = \\beta_0 \\cdot \\exp(x_i \\cdot \\beta_1)\\) \\(\\mu_i = \\beta_0 + x_i^{\\beta_1}\\) What is a linear model and what is not? 1.6.3 Vectorized notation Model equation form: \\(y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i\\) \\(\\varepsilon_i \\sim N(0, \\sigma^2),\\) Probability distribution form: Scalar \\(y_i \\sim N(\\mu_i, \\sigma^2),\\) \\(\\mu_i = \\beta_0 + \\beta_1 x_i\\) Vector \\(\\mathbf{y} \\sim N(\\boldsymbol{\\mu}, \\Sigma),\\) \\(\\boldsymbol{\\mu} = \\boldsymbol{1} \\beta_0 + \\mathbf{x} \\beta_1 = \\mathbf{X}\\boldsymbol{\\beta}\\) 1.6.4 Vectorized notation - cont. \\[\\begin{bmatrix}y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} \\sim N \\left( \\begin{bmatrix}\\mu_1 \\\\ \\mu_2 \\\\ \\vdots \\\\ \\mu_n \\end{bmatrix}, \\begin{bmatrix} Cov(y_1, y_1) &amp; Cov(y_1, y_2) &amp; \\dots &amp; Cov(y_1, y_n) \\\\ Cov(y_2, y_1) &amp; Cov(y_2, y_2) &amp; \\dots &amp; Cov(y_2, y_n)\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ Cov(y_n, y_1) &amp; Cov(y_n, y_2) &amp; \\dots &amp; Cov(y_n, y_n) \\end{bmatrix} \\right)\\] 1.6.5 Continuous and categorical predictors \\[\\mu_i = \\beta_0 + x_{1i} \\beta_1 + x_{2i} \\beta_2+ ... + x_{ji} \\beta_j\\] Discuss the following type of data: biomass cultivar county year 1.6.6 Three-step approach to writing a statistical model 1. What probability distribution function describes the data? Think about: type of data, support of the data. 2. Define a link function for the linear predictor. 3. Define the linear predictor. Treatments Design 1.7 Review 1.7.1 Probability distributions knitr::include_graphics(&quot;figures/distributions.png&quot;) 1.7.2 Mean, Variance Mean: the balancing point of a probability distribution Variance: dispersion of \\(y\\) set.seed(42) x &lt;- seq(-6, 6, length=100) hx &lt;- dnorm(x) labels &lt;- c(&quot;x ~ Normal(0, 1)&quot;, &quot;x ~ Normal(0, 16)&quot;, &quot;x ~ Normal(2, 1)&quot;) colors &lt;- c(&quot;darkgreen&quot;, &quot;tomato&quot;, &quot;purple&quot;) plot(x, dnorm(x, 0, 1), lwd=2, col= &quot;darkgreen&quot;, type=&quot;l&quot;, lty= 1, xlab=&quot;x&quot;, ylab=&quot;[x]&quot;) # lines(x, dnorm(x, 0, 1), lwd=2, col= &quot;darkgreen&quot;) lines(x, dnorm(x, 0, 4), lty = 2, lwd=2, col= &quot;tomato&quot;) lines(x, dnorm(x, 2, 1), lty = 3, lwd=2, col= &quot;purple&quot;) legend(&quot;topleft&quot;, inset=.05, title=&quot;Distributions&quot;, labels, lwd=2, lty=c(1, 2, 3), col=colors) What do these distributions mean in practice? options(bitmapType = &#39;cairo&#39;) library(gganimate) set.seed(123) n_total &lt;- 1000 steps &lt;- seq(20, n_total, by = 20) # add 20 points per frame full_data &lt;- rnorm(n_total, 0, 1) # create a long dataframe where each &#39;frame&#39; contains all points up to that index df_animated &lt;- bind_rows(lapply(steps, function(s) { data.frame( val = full_data[1:s], frame = s ) })) p &lt;- ggplot(df_animated, aes(x = val)) + geom_histogram( aes(y = after_stat(count)), bins = 30, fill = &quot;#B388EB&quot;, color = &quot;white&quot; ) + geom_point( aes(x = val, y = 0), alpha=.1, size = 2 )+ stat_function( fun = function(x) dnorm(x) * (max(steps)/30) * 4, color = &quot;black&quot;, size = 1, linetype = &quot;dashed&quot; ) + labs( title = &quot;Building a Normal Distribution&quot;, subtitle = &quot;Sample size (n): {closest_state}&quot;, x = &quot;x&quot;, y = &quot;[x]&quot; ) + theme_minimal() + transition_states(frame, transition_length = 2, state_length = 1) + ease_aes(&#39;sine-in-out&#39;) animate(p, nframes = length(steps), fps = 10, width = 6, height = 4, units = &quot;in&quot;, res =150, duration = 45, renderer = gifski_renderer()) 1.7.3 Covariance Covariance between two random variables means how the two random variables behave relative to each other. Essentially, it quantifies the relationship between their joint variability. The variance of a random variable is the covariance of a random variable with itself. Consider two variables \\(y1\\) and \\(y2\\) each with a variance of 1 and a covariance of 0.6. \\[\\begin{bmatrix}y_1 \\\\ y_2 \\end{bmatrix} \\sim MVN \\left( \\begin{bmatrix} 10 \\\\ 8 \\end{bmatrix} , \\begin{bmatrix}1 &amp; 0.6 \\\\ 0.6 &amp; 1 \\end{bmatrix} \\right),\\] where the means of \\(y_1\\) and \\(y_2\\) are 10 and 8, respectively, and their covariance structure is represented in the variance-covariance matrix. Remember: \\[\\begin{bmatrix}y_1 \\\\ y_2 \\end{bmatrix} \\sim MVN \\left( \\begin{bmatrix} E(y_1) \\\\ E(y_2) \\end{bmatrix} , \\begin{bmatrix} Var(y_1) &amp; Cov(y_1, y_2) \\\\ Cov(y_2,y_2) &amp; Var(y_2) \\end{bmatrix} \\right).\\] library(MASS) library(purrr) # 1. Setup Parameters set.seed(42) n_points &lt;- 1000 # Total points to plot steps &lt;- seq(1, n_points, by = 5) # Adding 5 points per frame for speed mu &lt;- c(10, 8) sigma &lt;- matrix(c(1, 0.6, 0.6, 1), 2) # 2. Generate the base data base_data &lt;- mvrnorm(n_points, mu = mu, Sigma = sigma) %&gt;% as.data.frame() %&gt;% rename(y1 = V1, y2 = V2) # 3. Create the cumulative dataset # Each &#39;frame&#39; will contain all points up to that index cum_data &lt;- map_df(steps, ~ { base_data[1:.x, ] %&gt;% mutate(frame = .x) }) # 4. Pre-calculate static marginal densities (same as before) x_seq &lt;- seq(7, 13.5, length.out = 100) df_x_dens &lt;- data.frame(x = x_seq, y = dnorm(x_seq, 10, 1) * 2 + 5) y_seq &lt;- seq(5, 11, length.out = 100) df_y_dens &lt;- data.frame(y = y_seq, x = dnorm(y_seq, 8, 1) * -2 + 7.8) # 5. Build the Plot p &lt;- ggplot(cum_data, aes(x = y1, y = y2)) + # Static layers: Red and Green indicators geom_segment(aes(x = 10, y = 5, xend = 10, yend = 8), color = &quot;tomato&quot;, linewidth = 1) + geom_segment(aes(x = 7, y = 8, xend = 10, yend = 8), color = &quot;darkgreen&quot;, linewidth = 1) + geom_path(data = df_x_dens, aes(x = x, y = y), color = &quot;tomato&quot;, linetype = &quot;dashed&quot;) + geom_path(data = df_y_dens, aes(x = x, y = y), color = &quot;darkgreen&quot;, linetype = &quot;dotted&quot;) + # Animated layer: Points stay because they exist in every subsequent frame geom_point(shape = 1, alpha = 0.6) + labs( title = &quot;Generatig Random Samples from a Bivariate Normal Distribution&quot;, subtitle = &quot;Sample Size: {closest_state}&quot;, x = TeX(&quot;$y_1$&quot;), y = TeX(&quot;$y_2$&quot;) ) + theme_minimal() + coord_cartesian(xlim = c(7, 13.5), ylim = c(5, 11)) + # transition_states tells R to switch between the &#39;frame&#39; groups transition_states(frame, transition_length = 0.5, state_length = 0.1) # 6. Render with fixed units to avoid the png() error options(bitmapType = &#39;cairo&#39;) animate( p, nframes = length(steps), fps = 12, width = 6, height = 4, units = &quot;in&quot;, res = 150, duration = 40, renderer = gifski_renderer() ) 1.8 The most common statistical model \\[\\mathbf{y} \\sim N(\\boldsymbol\\mu, \\boldsymbol\\Sigma),\\] where: \\(\\mathbf{y} \\equiv [y_1, y_2, \\dots, y_n]&#39;\\) contains the response data, \\(\\boldsymbol{\\mu} \\equiv [\\mu_1, \\mu_2, \\dots, \\mu_n]&#39;\\) contains the expected values of said data, \\(\\boldsymbol\\Sigma\\) is the variance-covariance matrix. The most typical model typically has: \\(\\boldsymbol\\mu = \\mathbf{X}\\boldsymbol{\\beta}\\) and \\(\\boldsymbol\\Sigma = \\sigma^2\\mathbf{I}\\). In summary, the assumptions are: Normality Independence Constant variance 1.8.1 Properties of the general linear model \\(E(\\hat{\\boldsymbol{\\beta}}) = \\boldsymbol{\\beta}\\) \\(\\text{Var}(\\hat{\\boldsymbol{\\beta}}) = \\frac{\\sigma^2}{\\mathbf{X}^T\\mathbf{X}} = \\sigma^2 (\\mathbf{X}^T\\mathbf{X})^{-1}\\) Class discussion: What if the observations weren’t independent? What if the variance wasn’t constant? 1.9 Uncertainty Uncertainty will be one of the central topics in this course. Uncertainty is important because, as we summarize the information (to aviod Funes’ uninformative excess of information), we also have to describe how certain a signal is. 1.9.1 Types of uncertainty Epistemological uncertainty Intrinsic uncertainty 1.9.2 Uncertainty - applied example Assume that the model \\(y_i \\sim N(\\mu_i, \\sigma^2), \\mu_i = \\beta_0 + \\beta_1 x_i+ \\beta_2 x_i^2\\) describes the data generating process. url &lt;- &quot;https://raw.githubusercontent.com/k-state-id3a/mixed-models-fall25/refs/heads/newpart3/data/nitrogen_yield.csv&quot; df_n_ss &lt;- read.csv(url) m1 &lt;- lm(Yield_SY ~ Total_N + I(Total_N^2), data = df_n_ss) DHARMa::simulateResiduals(m1, plot = T) ## Object of Class DHARMa with simulated residuals based on 250 simulations with refit = FALSE . See ?DHARMa::simulateResiduals for help. ## ## Scaled residual values: 0.1 0.3 0.004 0.588 0.792 0.556 0.168 0.344 0.256 0.452 0.388 0.388 0.832 0.94 0.692 0.936 0.132 0.312 0.424 0.664 ... m1 &lt;- lm(Yield_SY ~ Total_N + I(Total_N^2), data = df_n_ss) df_plot &lt;- data.frame(Total_N = 0:280) df_plot$yhat &lt;- predict(m1, newdata = df_plot) # estimation uncertainty confid_est &lt;- predict(m1, newdata = df_plot, se.fit = TRUE, interval = &quot;confidence&quot;) df_plot$est_low &lt;- (confid_est$fit)[,2] df_plot$est_up &lt;- (confid_est$fit)[,3] # estimation uncertainty confid_pred &lt;- predict(m1, newdata = df_plot, se.fit = TRUE, interval = &quot;predict&quot;) df_plot$pred_low &lt;- (confid_pred$fit)[,2] df_plot$pred_up &lt;- (confid_pred$fit)[,3] library(ggpubr) ## Warning: package &#39;ggpubr&#39; was built under R version 4.4.3 df_plot |&gt; ggplot(aes(Total_N, yhat))+ geom_ribbon(aes(ymin = pred_low, ymax = pred_up), alpha = .3, fill = &quot;#B388EB&quot;)+ geom_ribbon(aes(ymin = est_low, ymax = est_up), alpha = .6, fill = &quot;#B200EB&quot;)+ geom_line()+ labs(y = latex2exp::TeX(&quot;$\\\\hat{y}$&quot;), x = expression(Total~N~(lb~ac^{-1})))+ theme_pubclean() "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
